{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandasql as ps\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import LabelEncoder,OrdinalEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw\n",
    "train_val = pd.read_csv(\"/Users/jiamin/Documents/869 team project/Training_set_values.csv\")\n",
    "train_lbl = pd.read_csv(\"/Users/jiamin/Documents/869 team project/Training_set_labels.csv\")\n",
    "test_val = pd.read_csv(\"/Users/jiamin/Documents/869 team project/Test_set_values.csv\")\n",
    "\n",
    "# ordinal encoded raw\n",
    "train_prep = pd.read_csv(\"/Users/jiamin/Documents/869 team project/preprocessed data/train_data.csv\")\n",
    "test_prep = pd.read_csv(\"/Users/jiamin/Documents/869 team project/preprocessed data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_set = train_val.merge(train_lbl, on='id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ payment \n",
    "# bin 'other' category to 'unknown' group\n",
    "\n",
    "train_set.loc[train_set.payment_type == 'other', 'payment_type'] = 'unknown'\n",
    "\n",
    "Ord_enc = OrdinalEncoder()\n",
    "Ord_enc = Ord_enc.fit(train_set[['payment_type']])\n",
    "train_set['payment_type_ord'] = Ord_enc.transform(train_set[['payment_type']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# quality\n",
    "# 'good' has the highest number of all target -> create individual dummy\n",
    "\n",
    "train_set['quality_ind'] = np.where(train_set['water_quality'] == 'good',1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ construction year\n",
    "# bin years into new and old and create unknown for all the year = 0\n",
    "\n",
    "def construction(df):\n",
    "    if df['construction_year'] >= 1986:\n",
    "        val = 'New'\n",
    "    elif df['construction_year'] == 0:\n",
    "        val = 'Unknown'\n",
    "    else:\n",
    "        val = 'Old'\n",
    "    return val\n",
    "\n",
    "train_set['construction_cat'] = train_set.apply(construction, axis=1)\n",
    "train_set.drop('construction_year',axis=1)\n",
    "\n",
    "Ord_enc_2 = OrdinalEncoder()\n",
    "Ord_enc_2 = Ord_enc_2.fit(train_set[['construction_cat']])\n",
    "train_set['construction_cat'] = Ord_enc_2.transform(train_set[['construction_cat']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ permit \n",
    "# missing imputation and create dummy to indicate whether the value was imputed or not\n",
    "\n",
    "imp = SimpleImputer(missing_values = np.nan, strategy='median') \n",
    "train_set['permit_imp'] = imp.fit_transform(train_set[['permit']]).ravel()\n",
    "\n",
    "train_set['permit_imp_ind'] = np.where(train_set['permit'].isna(),1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ longitude\n",
    "#impute missing data to median of the same location (subvillage, ward, lga)\n",
    "\n",
    "train_set.loc[train_set.longitude == 0, 'longitude'] = np.nan\n",
    "train_set.longitude.fillna(train_set.groupby(['subvillage'])['longitude'].transform('median'), inplace = True)\n",
    "train_set.longitude.fillna(train_set.groupby(['ward'])['longitude'].transform('median'), inplace = True)\n",
    "train_set.longitude.fillna(train_set.groupby(['lga'])['longitude'].transform('median'), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ latitude\n",
    "#impute missing data to median of the same location (subvillage, ward, lga)\n",
    "\n",
    "train_set_latitude = train_set[train_set['latitude'].round(0) == -0]\n",
    "train_set.loc[train_set.latitude.round(0) == -0.0, 'latitude'] = np.nan\n",
    "train_set.latitude.fillna(train_set.groupby(['subvillage'])['latitude'].transform('median'), inplace = True)\n",
    "train_set.latitude.fillna(train_set.groupby(['ward'])['latitude'].transform('median'), inplace = True)\n",
    "train_set.latitude.fillna(train_set.groupby(['lga'])['latitude'].transform('median'), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ gps_height\n",
    "#impute missing data to mean of the same location (subvillage, ward, lga,region_code)\n",
    "\n",
    "train_set.loc[train_set.gps_height == 0, 'gps_height'] = np.nan\n",
    "train_set.gps_height.fillna(train_set.groupby(['subvillage'])['gps_height'].transform('mean'), inplace = True)\n",
    "train_set.gps_height.fillna(train_set.groupby(['ward'])['gps_height'].transform('mean'), inplace = True)\n",
    "train_set.gps_height.fillna(train_set.groupby(['lga'])['gps_height'].transform('mean'), inplace = True)\n",
    "train_set.gps_height.fillna(train_set.groupby(['region_code'])['gps_height'].transform('mean'), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ population\n",
    "#impute missing data to median of the same location (subvillage, ward, lga,region_code)\n",
    "train_set['popu_ind'] = np.where(train_set['population'] == 0,1,0)\n",
    "\n",
    "train_set.loc[train_set.population == 0, 'population'] = np.nan\n",
    "train_set.population.fillna(train_set.groupby(['subvillage'])['population'].transform('median'), inplace = True)\n",
    "train_set.population.fillna(train_set.groupby(['ward'])['population'].transform('median'), inplace = True)\n",
    "train_set.population.fillna(train_set.groupby(['lga'])['population'].transform('median'), inplace = True)\n",
    "train_set.population.fillna(train_set.groupby(['region_code'])['population'].transform('median'), inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(feature, title):\n",
    "    plt.figure(figsize=(8, 5));\n",
    "    plt.hist(feature, bins=200, edgecolor='black', linewidth=1.2);\n",
    "    plt.title(title, fontsize=20);\n",
    "    #ax.tick_params(axis='both', which='major', labelsize=18);\n",
    "    plt.grid(True);\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(train_set['population'], \"dist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_set[['population']])\n",
    "\n",
    "train_set['popu_Std'] = scaler.transform(train_set[['population']])   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(train_set['popu_Std'], \"Standard\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "scaler_log = FunctionTransformer(np.log1p, validate=True)\n",
    "scaler_log.fit(train_set[['popu_Std']])\n",
    "train_set['popu_StdLog'] = scaler_log.transform(train_set[['popu_Std']]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(train_set['popu_StdLog'], \"StdLog\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ fix typo installer\n",
    "\n",
    "def fix_typo(df):\n",
    "    df['installer'].replace(to_replace = ('ADRA /Government') , value ='ADRA/Government' , inplace=True)\n",
    "    df['installer'].replace(to_replace = ('British colonial government') , value ='British government' , inplace=True)\n",
    "    df['installer'].replace(to_replace = ('Central Government','Tanzania Government', 'central government','Cental Government', 'Cebtral Government', 'Tanzanian Government','Tanzania government', 'Centra Government', 'CENTRAL GOVERNMENT', 'TANZANIAN GOVERNMENT','Central govt', 'Centr', 'Centra govt') , value ='Central government' , inplace=True)\n",
    "    df['installer'].replace(to_replace =('Commu','Communit','commu','COMMU', 'COMMUNITY'), value ='Community' , inplace=True)\n",
    "    df['installer'].replace(to_replace = ('Concern /government') , value ='Concern/Government' , inplace=True)\n",
    "    df['installer'].replace(to_replace = ('Colonial Government') , value ='Colonial government' , inplace=True)\n",
    "    df['installer'].replace(to_replace = ('COUN', 'District COUNCIL', 'DISTRICT COUNCIL','District Counci', 'District Council','Council','Counc','District Council','Distri'), value ='District council' , inplace=True)\n",
    "    df['installer'].replace(to_replace = ('District Water Department', 'District water depar','Distric Water Department'), value ='District water department' , inplace=True)\n",
    "    df['installer'].replace(to_replace = 'DANID', value ='DANIDA' , inplace=True)\n",
    "    df['installer'].replace(to_replace = ('FinW','Fini water','FINI WATER'), value ='Fini Water' , inplace=True)\n",
    "    df['installer'].replace(to_replace = ('GOVERNMENT', 'GOVER', 'GOVERNME', 'GOVERM','GOVERN','Gover','Gove','Governme','Governmen' ) ,value ='Government' , inplace=True)\n",
    "    df['installer'].replace(to_replace = ('Government of Misri') , value ='Misri Government' , inplace=True)\n",
    "    df['installer'].replace(to_replace = ('Government and Community') , value ='Government /Community' , inplace=True)\n",
    "    df['installer'].replace(to_replace = ('Government /TCRS','Government/TCRS') , value ='TCRS /Government' , inplace=True)\n",
    "    df['installer'].replace(to_replace = 'Hesawa', value ='HESAWA' , inplace=True)\n",
    "    df['installer'].replace(to_replace = ('Italy government') , value ='Italian government' , inplace=True)\n",
    "    df['installer'].replace(to_replace = 'JAICA', value ='Jaica' , inplace=True)\n",
    "    df['installer'].replace(to_replace = ('RC CHURCH', 'RC Churc', 'RC','RC Ch','RC C', 'RC CH','RC church', 'RC CATHORIC',) , value ='RC Church' , inplace=True)\n",
    "    df['installer'].replace(to_replace = ('World vision', 'World Division','World Vision'), value ='world vision' , inplace=True)\n",
    "    df['installer'].replace(to_replace = ('Unisef','UNICEF'),value ='Unicef' , inplace=True)\n",
    "    df['installer'].replace(to_replace = ('villigers', 'villager', 'Villagers', 'Villa', 'Village', 'Villi', 'Village Council','Village Counil', 'Villages', 'Vill', 'Village community', 'Villaers', 'Village Community', 'Villag','Villege Council', 'Village council', 'Village Council','Villagerd', 'Villager', 'Village Technician', 'Village Office','Village community members'), value ='villagers' , inplace=True)\n",
    "    df['installer'].replace(to_replace = ('Village Government') , value ='Village government' , inplace=True)\n",
    "    df['installer'].replace(to_replace = ('Cetral government /RC') , value ='RC church/Central Gover' , inplace=True)\n",
    "    return df\n",
    "\n",
    "train_set= fix_typo(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ installer\n",
    "train_set.installer.fillna('other', inplace=True)\n",
    "train_set.loc[train_set.installer.str.len() == 1, 'installer'] = 'other'\n",
    "\n",
    "Ord_enc_installer = OrdinalEncoder()\n",
    "Ord_enc_installer = Ord_enc_installer.fit(train_set[['installer']])\n",
    "train_set['installer_ord'] = Ord_enc_installer.transform(train_set[['installer']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## funder\n",
    "train_set['funder'].replace(to_replace = '0', value ='None' , inplace=True)\n",
    "train_set['funder'].replace(to_replace = 'Unknown', value ='None' , inplace=True)\n",
    "\n",
    "columns_to_keep = ['Government Of Tanzania','Unknown','Danida','Hesawa','Rwssp','World Bank','Kkkt', 'World Vision',\n",
    "         'Unicef','Tasaf','District Council', 'Dhv', 'Private Individual', 'Dwsp','Norad','Germany Republi',\n",
    "         'Tcrs','Ministry Of Water','Water','Dwe']\n",
    "\n",
    "train_set.loc[~train_set[\"funder\"].isin(columns_to_keep), \"funder\"] = \"Others\"\n",
    "train_set['funder'] = train_set['funder'].astype(\"category\").cat.remove_unused_categories()\n",
    "\n",
    "\n",
    "Ord_enc_funder = OrdinalEncoder()\n",
    "Ord_enc_funder = Ord_enc_funder.fit(train_set[['funder']])\n",
    "train_set['funder_ord'] = Ord_enc_funder.transform(train_set[['funder']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# subvillage\n",
    "# train_set.loc[train_set.subvillage.isnull(), 'subvillage'] = 'unknown'\n",
    "# train_set.subvillage.value_counts()[:20]\n",
    "\n",
    "\n",
    "# print(ps.sqldf(\"select subvillage,count(*) as num from train_set \\\n",
    "# group by subvillage\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# scheme_management\n",
    "\n",
    "train_set.loc[train_set.scheme_management == 'None', 'scheme_management'] = 'Other'\n",
    "imp2 = SimpleImputer(missing_values = np.nan, strategy='most_frequent') \n",
    "train_set['scheme_management'] = imp2.fit_transform(train_set[['scheme_management']]).ravel()\n",
    "\n",
    "Ord_enc_3 = OrdinalEncoder()\n",
    "Ord_enc_3 = Ord_enc.fit(train_set[['scheme_management']])\n",
    "train_set['scheme_management_ord'] = Ord_enc_3.transform(train_set[['scheme_management']])\n",
    "\n",
    "# print(ps.sqldf(\"select scheme_management,count(*) as num from train_set \\\n",
    "#  group by scheme_management\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# public_meeting\n",
    "\n",
    "train_set['public_meeting'].astype('float')\n",
    "train_set.loc[train_set.public_meeting.isnull(), 'public_meeting'] = 2\n",
    "# print(ps.sqldf(\"select public_meeting,count(*) as num from train_set \\\n",
    "#  group by public_meeting\"))\n",
    "\n",
    "train_set['public_meeting']= train_set['public_meeting'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numerical: lga, ward, region, longitude, latitude,gps_height,population\n",
    "categorcial: basin,installer, extraction_type_class, management_group, source, waterpoint_type, quality_group,public_meeting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prep = pd.read_csv(\"/Users/jiamin/Documents/869 team project/preprocessed data/train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine datasets\n",
    "train_set_pre = train_set[['quality_ind',\n",
    "                           'construction_cat',\n",
    "                           'permit_imp',\n",
    "                           'permit_imp_ind',\n",
    "                           'id',\n",
    "                           'payment_type_ord',\n",
    "                           'longitude',\n",
    "                           'latitude',\n",
    "                           'gps_height',\n",
    "                           'population',\n",
    "                           'popu_ind',                 \n",
    "                           'popu_Std',               \n",
    "                            'popu_StdLog',           \n",
    "                            'installer_ord',           \n",
    "                            'funder_ord',              \n",
    "                            'scheme_management_ord', \n",
    "                           'public_meeting',\n",
    "                           'status_group']]\n",
    "\n",
    "\n",
    "\n",
    "train_set_ord = train_prep.drop(['construction_year',\n",
    "                                 'permit',\n",
    "                                 'amount_tsh',\n",
    "                                 'gps_height',\n",
    "                                 'longitude',\n",
    "                                 'latitude',\n",
    "                                 'population',\n",
    "                                 'funder',\n",
    "                                 'installer',\n",
    "                                 'wpt_name',\n",
    "                                 'num_private',\n",
    "                                 'date_recorded','recorded_by',\n",
    "                                 'subvillage',\n",
    "                                 'region_code','district_code',\n",
    "                                 'extraction_type','extraction_type_group',\n",
    "                                 'scheme_management','scheme_name',\n",
    "                                 'public_meeting',\n",
    "                                 'management',\n",
    "                                 'water_quality',\n",
    "                                 'payment_type','payment',\n",
    "                                 'quantity_group',\n",
    "                                 'source_type','source_class',\n",
    "                                 'waterpoint_type_group',\n",
    "                                 'status_group'],axis=1)\n",
    "\n",
    "train_full = train_set_pre.merge(train_set_ord, on='id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test control split\n",
    "train_full_y = train_full['status_group']\n",
    "train_full_x = train_full.drop(['status_group'], axis=1)\n",
    "train_full_x_train, train_full_x_test, train_full_y_train, train_full_y_test = train_test_split(train_full_x, train_full_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full_x_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "      \"learning_rate\": 0.03,\n",
    "      \"max_depth\": 6,\n",
    "      \"min_child_samples\": 63,\n",
    "      \"min_data_per_group\": 100,\n",
    "      \"n_estimators\": 200,\n",
    "      \"num_leaves\": 63,\n",
    "      \"reg_alpha\":  0.05,\n",
    "      \"reg_lambda\": 0.05,\n",
    "      \"subsample\": 0.8,\n",
    "      \"boosting_type\": 'gbtree',\n",
    "      \"n_jobs\": 1,\n",
    "      \"verbosity\": 0,\n",
    "      \"seed\": 77,\n",
    "    \"is_unbalance\": True,\n",
    "}\n",
    "\n",
    "estimator_v1 = XGBClassifier(**params)\n",
    "estimator_v1 = estimator_v1.fit(train_full_x_train, train_full_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "estimator_v2 = XGBClassifier(objective = 'multi:softmax', booster = 'gbtree', nrounds = 'min.error.idx',\n",
    "                        num_class = 3, maximize = False, eval_metric = 'merror', eta = .1,\n",
    "                        max_depth = 10, colsample_bytree = .4, n_jobs = -1,learning_rate = 0.05, verbose=2,\n",
    "                             is_unbalance = True)\n",
    "\n",
    "estimator_v2 = estimator_v2.fit(train_full_x_train, train_full_y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "estimator_v3 = XGBClassifier(nthread=2, num_class=3, \n",
    "                        min_child_weight=3, max_depth=15,\n",
    "                        gamma=0.5, scale_pos_weight=0.8,\n",
    "                        subsample=0.7, colsample_bytree = 0.8,\n",
    "                        objective='multi:softmax',\n",
    "                            is_unbalance = True)\n",
    "\n",
    "estimator_v3 = estimator_v3.fit(train_full_x_train, train_full_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Scores:\n",
      "['0.7979', '0.7911', '0.7975', '0.7989', '0.7955']\n",
      "CV Score mean: 0.7962 \n",
      "CV Score range: 0.7934 -- 0.7989\n"
     ]
    }
   ],
   "source": [
    "# cross validation\n",
    "inner_cv_scores = cross_validate(estimator_v3, train_full_x_train, train_full_y_train, \n",
    "                                 cv=5, \n",
    "                                 scoring=\"accuracy\", \n",
    "                                 n_jobs=15, \n",
    "                                 verbose=0, \n",
    "                                 return_train_score=True)\n",
    "\n",
    "cv_scores=inner_cv_scores['test_score'].tolist()\n",
    "fit_times=inner_cv_scores['fit_time'].tolist()\n",
    "\n",
    "print(\"CV Scores:\")\n",
    "print([\"{:0.4f}\".format(cv_score) for cv_score in cv_scores])\n",
    "print(\"CV Score mean: {:.4f} \".format(np.mean(cv_scores)))\n",
    "print(\"CV Score range: {:0.4f} -- {:0.4f}\".format(np.mean(cv_scores) - np.std(cv_scores), np.mean(cv_scores) + np.std(cv_scores)))\n",
    "\n",
    "#v2\n",
    "# CV Scores:\n",
    "# ['0.8018', '0.7980', '0.7984', '0.7993', '0.7947']\n",
    "# CV Score mean: 0.7984 \n",
    "# CV Score range: 0.7962 -- 0.8007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.81      0.88      0.84      6457\n",
      "functional needs repair       0.50      0.37      0.42       851\n",
      "         non functional       0.84      0.77      0.80      4572\n",
      "\n",
      "               accuracy                           0.80     11880\n",
      "              macro avg       0.71      0.67      0.69     11880\n",
      "           weighted avg       0.80      0.80      0.80     11880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#########rf\n",
    "\n",
    "rf_clf_v1 = RandomForestClassifier(n_estimators=400, max_depth=None,\n",
    "                                    min_samples_split = 4,\n",
    "                                    max_features = 'auto',\n",
    "                                    max_leaf_nodes= None,\n",
    "                                    class_weight = 'balanced',\n",
    "                                    random_state = 42)\n",
    "rf_clf_v1.fit(train_full_x_train, train_full_y_train)\n",
    "\n",
    "\n",
    "\n",
    "rf_pred_v1 = rf_clf_v1.predict(train_full_x_test)\n",
    "class_names = [str(x) for x in rf_clf_v1.classes_]\n",
    "\n",
    "\n",
    "\n",
    "print(classification_report(train_full_y_test, rf_pred_v1, target_names = class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_val.loc[test_val.payment_type == 'other', 'payment_type'] = 'unknown'\n",
    "Ord_enc = Ord_enc.fit(test_val[['payment_type']])\n",
    "test_val['payment_type_ord'] = Ord_enc.transform(test_val[['payment_type']])\n",
    "\n",
    "test_val['quality_ind'] = np.where(test_val['quality_group'] == 'good',1,0)\n",
    "\n",
    "test_val['construction_cat'] = test_val.apply(construction, axis=1)\n",
    "Ord_enc_2 = Ord_enc_2.fit(test_val[['construction_cat']])\n",
    "test_val['construction_cat'] = Ord_enc_2.transform(test_val[['construction_cat']])\n",
    "\n",
    "test_val['permit_imp'] = imp.fit_transform(test_val[['permit']]).ravel()\n",
    "test_val['permit_imp_ind'] = np.where(test_val['permit'].isna(),1,0)\n",
    "\n",
    "test_val.loc[test_val.longitude == 0, 'longitude'] = np.nan\n",
    "test_val.longitude.fillna(test_val.groupby(['subvillage'])['longitude'].transform('median'), inplace = True)\n",
    "test_val.longitude.fillna(test_val.groupby(['ward'])['longitude'].transform('median'), inplace = True)\n",
    "test_val.longitude.fillna(test_val.groupby(['lga'])['longitude'].transform('median'), inplace = True)\n",
    "\n",
    "test_val_latitude = test_val[test_val['latitude'].round(0) == -0]\n",
    "test_val.loc[test_val.latitude.round(0) == -0.0, 'latitude'] = np.nan\n",
    "test_val.latitude.fillna(test_val.groupby(['subvillage'])['latitude'].transform('median'), inplace = True)\n",
    "test_val.latitude.fillna(test_val.groupby(['ward'])['latitude'].transform('median'), inplace = True)\n",
    "test_val.latitude.fillna(test_val.groupby(['lga'])['latitude'].transform('median'), inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_val.loc[test_val.gps_height == 0, 'gps_height'] = np.nan\n",
    "test_val.gps_height.fillna(test_val.groupby(['subvillage'])['gps_height'].transform('mean'), inplace = True)\n",
    "test_val.gps_height.fillna(test_val.groupby(['ward'])['gps_height'].transform('mean'), inplace = True)\n",
    "test_val.gps_height.fillna(test_val.groupby(['lga'])['gps_height'].transform('mean'), inplace = True)\n",
    "test_val.gps_height.fillna(test_val.groupby(['region_code'])['gps_height'].transform('mean'), inplace=True)\n",
    "\n",
    "test_val['popu_ind'] = np.where(test_val['population'] == 0,1,0)\n",
    "test_val.loc[test_val.population == 0, 'population'] = np.nan\n",
    "test_val.population.fillna(test_val.groupby(['subvillage'])['population'].transform('median'), inplace = True)\n",
    "test_val.population.fillna(test_val.groupby(['ward'])['population'].transform('median'), inplace = True)\n",
    "test_val.population.fillna(test_val.groupby(['lga'])['population'].transform('median'), inplace = True)\n",
    "test_val.population.fillna(test_val.groupby(['region_code'])['population'].transform('median'), inplace=True)\n",
    "\n",
    "scaler.fit(test_val[['population']])\n",
    "test_val['popu_Std'] = scaler.transform(test_val[['population']])\n",
    "scaler_log.fit(test_val[['popu_Std']])\n",
    "test_val['popu_StdLog'] = scaler_log.transform(test_val[['popu_Std']])\n",
    "\n",
    "test_val= fix_typo(test_val)\n",
    "test_val.installer.fillna('other', inplace=True)\n",
    "test_val.loc[test_val.installer.str.len() == 1, 'installer'] = 'other'\n",
    "Ord_enc_installer = Ord_enc_installer.fit(test_val[['installer']])\n",
    "test_val['installer_ord'] = Ord_enc_installer.transform(test_val[['installer']])\n",
    "\n",
    "### funder\n",
    "test_val['funder'].replace(to_replace = '0', value ='None' , inplace=True)\n",
    "test_val['funder'].replace(to_replace = 'Unknown', value ='None' , inplace=True)\n",
    "columns_to_keep = ['Government Of Tanzania','Unknown','Danida','Hesawa','Rwssp','World Bank','Kkkt', 'World Vision',\n",
    "                    'Unicef','Tasaf','District Council', 'Dhv', 'Private Individual', 'Dwsp','Norad','Germany Republi',\n",
    "                    'Tcrs','Ministry Of Water','Water','Dwe']\n",
    "test_val.loc[~test_val[\"funder\"].isin(columns_to_keep), \"funder\"] = \"Others\"\n",
    "test_val['funder'] = test_val['funder'].astype(\"category\").cat.remove_unused_categories()\n",
    "Ord_enc_funder = Ord_enc_funder.fit(test_val[['funder']])\n",
    "test_val['funder_ord'] = Ord_enc_funder.transform(test_val[['funder']])\n",
    "\n",
    "###### scheme_management\n",
    "test_val.loc[test_val.scheme_management == 'None', 'scheme_management'] = 'Other'\n",
    "imp2 = SimpleImputer(missing_values = np.nan, strategy='most_frequent')\n",
    "test_val['scheme_management'] = imp2.fit_transform(test_val[['scheme_management']]).ravel()\n",
    "Ord_enc_3 = Ord_enc.fit(test_val[['scheme_management']])\n",
    "test_val['scheme_management_ord'] = Ord_enc_3.transform(test_val[['scheme_management']])\n",
    "\n",
    "\n",
    "test_val['public_meeting'].astype('float')\n",
    "test_val.loc[test_val.public_meeting.isnull(), 'public_meeting'] = 2\n",
    "test_val['public_meeting']= test_val['public_meeting'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14850 entries, 0 to 14849\n",
      "Data columns (total 27 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   quality_ind            14850 non-null  int64  \n",
      " 1   construction_cat       14850 non-null  float64\n",
      " 2   permit_imp             14850 non-null  float64\n",
      " 3   permit_imp_ind         14850 non-null  int64  \n",
      " 4   id                     14850 non-null  int64  \n",
      " 5   payment_type_ord       14850 non-null  float64\n",
      " 6   longitude              14850 non-null  float64\n",
      " 7   latitude               14850 non-null  float64\n",
      " 8   gps_height             14850 non-null  float64\n",
      " 9   population             14850 non-null  float64\n",
      " 10  popu_ind               14850 non-null  int64  \n",
      " 11  popu_Std               14850 non-null  float64\n",
      " 12  popu_StdLog            14850 non-null  float64\n",
      " 13  installer_ord          14850 non-null  float64\n",
      " 14  funder_ord             14850 non-null  float64\n",
      " 15  scheme_management_ord  14850 non-null  float64\n",
      " 16  public_meeting         14850 non-null  float64\n",
      " 17  basin                  14850 non-null  int64  \n",
      " 18  region                 14850 non-null  int64  \n",
      " 19  lga                    14850 non-null  int64  \n",
      " 20  ward                   14850 non-null  int64  \n",
      " 21  extraction_type_class  14850 non-null  int64  \n",
      " 22  management_group       14850 non-null  int64  \n",
      " 23  quality_group          14850 non-null  int64  \n",
      " 24  quantity               14850 non-null  int64  \n",
      " 25  source                 14850 non-null  int64  \n",
      " 26  waterpoint_type        14850 non-null  int64  \n",
      "dtypes: float64(13), int64(14)\n",
      "memory usage: 3.2 MB\n"
     ]
    }
   ],
   "source": [
    "test_set_pre = test_val[['quality_ind',\n",
    "                           'construction_cat',\n",
    "                           'permit_imp',\n",
    "                           'permit_imp_ind',\n",
    "                           'id',\n",
    "                           'payment_type_ord',\n",
    "                           'longitude',\n",
    "                           'latitude',\n",
    "                           'gps_height',\n",
    "                           'population',\n",
    "                           'popu_ind',                 \n",
    "                           'popu_Std',               \n",
    "                            'popu_StdLog',           \n",
    "                            'installer_ord',           \n",
    "                            'funder_ord',              \n",
    "                            'scheme_management_ord', \n",
    "                           'public_meeting']]\n",
    "\n",
    "test_set_ord = test_prep.drop(['construction_year',\n",
    "                                 'permit',\n",
    "                                 'amount_tsh',\n",
    "                                 'gps_height',\n",
    "                                 'longitude',\n",
    "                                 'latitude',\n",
    "                                 'population',\n",
    "                                 'funder',\n",
    "                                 'installer',\n",
    "                                 'wpt_name',\n",
    "                                 'num_private',\n",
    "                                 'date_recorded','recorded_by',\n",
    "                                 'subvillage',\n",
    "                                 'region_code','district_code',\n",
    "                                 'extraction_type','extraction_type_group',\n",
    "                                 'scheme_management','scheme_name',\n",
    "                                 'public_meeting',\n",
    "                                 'management',\n",
    "                                 'water_quality',\n",
    "                                 'payment_type','payment',\n",
    "                                 'quantity_group',\n",
    "                                 'source_type','source_class',\n",
    "                                 'waterpoint_type_group'\n",
    "                              ],axis=1)\n",
    "\n",
    "test_full = test_set_pre.merge(test_set_ord, on='id',how='left')\n",
    "test_full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_full['status_group'] = ''\n",
    "full_set = pd.concat([train_full,test_full])\n",
    "\n",
    "full_prep_train = full_set[full_set.status_group != '']\n",
    "full_prep_test = full_set[full_set.status_group == ''] \n",
    "\n",
    "full_prep_train_x = full_prep_train.drop(['status_group'], axis=1)\n",
    "full_prep_train_y = full_prep_train['status_group']\n",
    "full_prep_test_x = full_prep_test.drop(['status_group'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status_group\n",
      "functional                 9916\n",
      "functional needs repair     183\n",
      "non functional             4751\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "estimator_v2 = estimator_v2.predict(full_prep_test_x )\n",
    "pred_v1 = pd.DataFrame(estimator_v2,columns = ['status_group'])\n",
    "\n",
    "pred_v1['id'] = test_val['id']\n",
    "pred_v1 = pred_v1[['id','status_group']]\n",
    "print(pred_v1.groupby('status_group').size())\n",
    "\n",
    "# status_group\n",
    "# functional                 10359\n",
    "# functional needs repair      171\n",
    "# non functional              4320\n",
    "# dtype: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf_v7 = RandomForestClassifier(n_estimators=800, max_depth=None, \n",
    "                                   min_samples_split = 4, \n",
    "                                   max_features = 'auto',\n",
    "                                   max_leaf_nodes= None,\n",
    "                                   class_weight = 'balanced',\n",
    "                                   random_state = 42)\n",
    "\n",
    "rf_clf_v7.fit(full_prep_train_x, full_prep_train_y)\n",
    "rf_clf_v7 = rf_clf_v7.predict(full_prep_test_x)\n",
    "\n",
    "#n_estimators=800: 0.8061\n",
    "#n_estimators=400: 0.8054\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status_group\n",
      "functional                 9180\n",
      "functional needs repair     460\n",
      "non functional             5210\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "pred_v7 = pd.DataFrame(rf_clf_v7,columns = ['status_group'])\n",
    "\n",
    "pred_v7['id'] = test_val['id']\n",
    "pred_v7 = pred_v7[['id','status_group']]\n",
    "print(pred_v7.groupby('status_group').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_v1.to_csv(\"/Users/jiamin/Desktop/output_v2nov20_xgb.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
